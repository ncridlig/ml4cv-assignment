================================================================================
MAXIMUM SOFTMAX PROBABILITY (MSP) ANOMALY DETECTION RESULTS
================================================================================

CONFIGURATION
--------------------------------------------------------------------------------
Model: models/deeplabv3_resnet50_augmented_10_47_09-11-25_mIoU_5026.pth
Test set: StreetHazards (1500 images)
Anomaly class: 13
Max pixels for evaluation: 1,000,000 (random subsampling)
Random seed: 42 (for reproducibility)

METHOD DESCRIPTION
--------------------------------------------------------------------------------
MSP uses softmax-normalized probabilities instead of raw logits.
Unlike Max Logits which only considers the maximum logit,
MSP considers ALL logits through the softmax denominator.
This penalizes predictions where multiple classes have similar probabilities.

RESULTS
--------------------------------------------------------------------------------
AUROC: 0.8671 (86.71%)
AUPR:  0.0621 (6.21%)
FPR95: 0.3357 (33.57%)
F1:    0.1167 (11.67%)
Optimal Threshold: -0.4993

BASELINE COMPARISON (Authors' Results)
--------------------------------------------------------------------------------
Metric          Your Model        Baseline      Difference
--------------------------------------------------------------------------------
FPR95               33.57%          26.50%          +7.07%
AUROC               86.71%          89.30%          -2.59%
AUPR                 6.21%          10.60%          -4.39%

METRIC EXPLANATIONS
--------------------------------------------------------------------------------
AUROC (Area Under ROC Curve):
  Measures the model's ability to rank anomaly scores correctly.
  Range: 0.5 (random) to 1.0 (perfect)
  Interpretation: Overall ranking quality across all thresholds.

AUPR (Area Under Precision-Recall Curve):
  Primary metric for imbalanced anomaly detection.
  Better than AUROC for datasets with rare anomalies (<2%).
  Interpretation: Trade-off between precision and recall.

FPR95 (False Positive Rate at 95% True Positive Rate):
  Answers: 'To detect 95% of anomalies, what % of normal pixels
  will be incorrectly flagged as anomalies?'
  Lower is better (fewer false alarms at high recall).
  Important for safety-critical applications (autonomous driving).
  Your result: 33.6% of normal pixels are false alarms
               to achieve 95% anomaly detection.

F1 Score:
  Harmonic mean of precision and recall at optimal threshold.
  Balances false positives and false negatives.
  Interpretation: Overall detection quality at best operating point.

================================================================================
